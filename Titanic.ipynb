{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.data_handling import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import Imputer, LabelBinarizer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712 train + 179 test\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.join(\"datasets\", \"titanic-train.csv\")\n",
    "passengers_raw = pd.read_csv(csv_path)\n",
    "\n",
    "train_set, test_set = train_test_split(passengers_raw, test_size=0.2, random_state=32)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")\n",
    "train_set = train_set.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1)\n",
    "test_set = test_set.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', Imputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "class_encoder = PipelineLabelBinarizer()\n",
    "class_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector([\"Pclass\"])),\n",
    "    ('label_binarizer', class_encoder)\n",
    "])\n",
    "\n",
    "sex_encoder = PipelineLabelBinarizer()\n",
    "sex_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector([\"Sex\"])),\n",
    "    ('label_binarizer', sex_encoder)\n",
    "])\n",
    "\n",
    "embarked_encoder = PipelineLabelBinarizer()\n",
    "embarked_pipeline = Pipeline([\n",
    "    ('fillna', FillNaWith([\"Embarked\"])),\n",
    "    ('selector', DataFrameSelector([\"Embarked\"])),\n",
    "    ('label_binarizer', embarked_encoder)\n",
    "])\n",
    "\n",
    "cabin_transformer = CabinTransformer()\n",
    "cabin_pipeline = Pipeline([\n",
    "    ('fillna', FillNaWith([\"Cabin\"], '')),\n",
    "    ('selector', DataFrameSelector([\"Cabin\"])),\n",
    "    ('cabin_transformer', cabin_transformer)\n",
    "])\n",
    "\n",
    "combined_features = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"class_pipeline\", class_pipeline),\n",
    "    (\"sex_pipeline\", sex_pipeline),\n",
    "    (\"embarked_pipeline\", embarked_pipeline),\n",
    "    (\"cabin_pipeline\", cabin_pipeline)\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', RandomForestClassifier(max_features=16, n_estimators=70))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelBinarizer();\n",
    "train_set_labels = unwrap_labels(labelEncoder.fit_transform(train_set[\"Survived\"].values))\n",
    "\n",
    "full_pipeline = full_pipeline.fit(train_set, train_set_labels)\n",
    "\n",
    "attributes = num_attribs + list(class_encoder.classes_) + list(sex_encoder.classes_) + list(embarked_encoder.classes_) + cabin_transformer.get_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  142\n",
      "%Correct:  79.3296089385\n",
      "ROC AUC:  0.866979655712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86697965571205016"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_labels = unwrap_labels(labelEncoder.transform(test_set[\"Survived\"].values))\n",
    "\n",
    "predict(full_pipeline, test_set, np.asarray(test_set_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  145\n",
      "%Correct:  81.0055865922\n",
      "ROC AUC:  0.872717788211\n",
      "Best Params:  {'clf__max_features': 12, 'clf__n_estimators': 60}\n",
      "Feature Importances: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.27952681992288586, 'female'),\n",
       " (0.2169199996672522, 'Age'),\n",
       " (0.20147457463252882, 'Fare'),\n",
       " (0.06741481157515003, 3),\n",
       " (0.06470184462025115, 'X'),\n",
       " (0.050746103843586146, 'SibSp'),\n",
       " (0.026833408835072455, 'Parch'),\n",
       " (0.014694437652850664, 'T'),\n",
       " (0.014106234574671955, 'Q'),\n",
       " (0.012022461456745891, 'male'),\n",
       " (0.010575733921454698, 2),\n",
       " (0.0094473118490239153, 1),\n",
       " (0.005591789076296292, 'cabin_number'),\n",
       " (0.0050890905319605764, 'B'),\n",
       " (0.0049958489888534572, 'Null'),\n",
       " (0.0047444199623553861, 'S'),\n",
       " (0.0032257152887395098, 'D'),\n",
       " (0.0031956073175367652, 'A'),\n",
       " (0.0028782566932597227, 'C'),\n",
       " (0.0010851510124744461, 'E'),\n",
       " (0.00059693331908708045, 'F'),\n",
       " (0.00013344525796297162, 'G'),\n",
       " (0.0, 'C')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'clf__n_estimators': [50, 60], 'clf__max_features': [12]},\n",
    "    # {'clf__n_estimators': [50, 60, 70], 'clf__max_features': [12, 14, 16]},\n",
    "    # {'clf__bootstrap': [False], 'clf__n_estimators': [20, 50, 80], 'clf__max_features': [4, 10, 16]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_set, train_set_labels)\n",
    "\n",
    "predict(grid_search.best_estimator_, test_set, test_set_labels)\n",
    "print(\"Best Params: \", grid_search.best_params_)\n",
    "\n",
    "feature_importances = grid_search.best_estimator_.named_steps['clf'].feature_importances_\n",
    "named_feature_importances = sorted(zip(feature_importances, attributes), reverse=True)\n",
    "print(\"Feature Importances: \")\n",
    "named_feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "passengers_raw_labels = unwrap_labels(LabelBinarizer().fit_transform(passengers_raw[\"Survived\"].values))\n",
    "full_pipeline = full_pipeline.fit(passengers_raw, passengers_raw_labels)\n",
    "\n",
    "submission_data_raw = pd.read_csv(\"datasets/titanic-test.csv\")\n",
    "predictions = full_pipeline.predict(submission_data_raw)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = submission_data_raw.PassengerId\n",
    "submission['Survived'] = predictions\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "filename = now.strftime(\"%Y%m%d-%H%M%S\") + '-submission_clucas.csv'\n",
    "submission.to_csv(path_or_buf='submissions/'+filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
